# freeCodeCamp.org

Prompt Engineering Tutorial – Master ChatGPT and LLM Responses

## Notas

* **Ingeniería de prompts**: surge en el auge de la inteligencia artificial y envuelve la escritura humana para refinar y optimizar prompts de forma estructurada.
* Su fin es perfeccionar la interacción entre la inteligencia artificial y el ser humano.
* **Inteligencia artificial**: es la simulación de procesos de inteligencia humana mediante máquinas.
* **Machine learning** (aprendizaje automático): se suele decir IA, funciona mediante el uso de grandes cantidades de datos y se analizan para buscar correlaciones o patrones. Estos patrones se utilizan para predecir resultados en función de los datos de entrenamiento proporcionados.
* La **IA generativa** es un tipo de inteligencia artificial que crea contenido nuevo a partir de datos de entrenamiento.
* **Lingüística**: es el estudio del lenguaje, se centra desde la estructura del lenguaje, fonética y hasta como se producen y perciben los sonidos del habla.
  * Fonética: estudia como se producen y perciben los sonidos.
  * Fonología: estudia los patrones y cambios de los sonidos.
  * Morfología: estudia la estructura de las palabras.
  * Sintaxis: estudia la estructura de las oraciones.
  * Semántica: estudia el significado lingüístico.
  * Pragmática: estudia como se utiliza el lenguaje en un contexto.
  * Histórica: estudia el cambio del lenguaje.
  * Sociolingüística: estudia la relación entre el lenguaje y la sociedad.
  * Computacional: estudia como las computadoras pueden procesar el lenguaje humano.
  * Psicolingüística: estudia como los humanos adquieren y utilizan el lenguaje.
* Conocer la lingüística permite elaborar indicaciones efectivas para que la IA muestre resultados más precisos.
* **Modelos de lenguaje**: es un programa inteligente que aprende de una amplia colección de textos escritos para recopilar como los humanos utilizan el lenguaje. Analiza las oraciones, su orden, significados y la forma en que encajan. Luego genera una predicción o continuación de las oraciones en base a su comprensión del lenguaje. Aunque aún dependen del ser humano para crearlas y entrenarlas.
* **Eliza**: es uno de los primeros programas informáticos de procesamiento de lenguaje natural creado entre 1964 y 1966 en el MIT por Joseph Weizenbaum. Fue diseñada para simular una conversión con el ser humano (simulaba ser un psicoterapeuta). Seguía un conjunto de reglas predefinidas. Sirvió como un método para explorar la comunicación entre humanos y máquinas.
* **Shrdlu**: es un programa creado entre 1968 y 1969 en el MIT por Terry Winograd el cual podía comprender comandos simples e interactuar con un mundo virtual de bloques. Estableció las bases para la idea de que las máquinas comprendieran el lenguaje humano.
* Los verdaderos modelos de lenguaje surgen en 2010 cuando entró en juego el aprendizaje profundo y las redes neuronales.
* **GPT** (Generative Pre-trained Transformer): surgida en el 2018 y creada por la compañía OpenAI, fue entrenado por una gran cantidad de datos de textos absorbiendo conocimientos (libros, artículos, libros e internet).
  * GPT-1: es la muestra de un modelo de lenguaje.
  * GPT-2: lanzada en 2019.
  * GPT-3: lanzada en 2020 (175 mil millones de parámetros).
  * GPT-4: entrenado con internet en lugar de grandes cantidades de datos obsoletos.
* **Ollama**: es un servicio que permite instalar, configurar y ejecutar modelos de lenguaje.
* **GPT-4** procesa todos los textos en fragmentos llamados **tokens** que representa 4 caracteres o 0.75 palabras.
* Buenas prácticas para escribir un prompt de instrucciones:
  * Escribir instrucciones claras y con detalles en la consulta.
  * Adoptar una personalidad.
  * Especificar el formato mediante indicaciones iterativas (darle seguimiento a la respuesta si no es lo que esperábamos o tiene varias partes).
  * Evitar adelantar la respuesta (no decir la respuesta que estamos esperando). 
  * Limitar o desglosar el alcance de temas largos o amplios para obtener una respuesta más específica.
* No asumir que la IA sabe de lo que estamos hablando.
* **Prompts de cero disparos**: aprovechan la comprensión de las palabras y las relaciones conceptuales de un modelo previamente entrenado sin necesidad de entrenamiento adicional (no necesita ejemplos explícitos).
* **Prompts de pocos disparos**: mejoran el modelo del lenguaje con ejemplos de entrenamiento a través de indicaciones que evitan el reentrenamiento
* **Alucinaciones de la IA**: son respuestas imprecisas cuando un modelo de lenguaje mal interpreta los datos. Son conexiones creativas que se generan al interpretar nuevos datos basándose en los datos que cuenta o ha visto.
* **Vectores/Texto embebido**: en la rama del aprendizaje automático y el procesamiento natural del lenguaje (NLP), el texto embebido es una técnica popular para representar información textual en un formato que puede ser procesado fácilmente por algoritmos, especialmente en modelos de aprendizaje profundo (LLM). Un vector embebido es una array de palabras que son más probables para mostrar un resultado más preciso.

## Referencias

* [freeCodeCamp.org - Prompt Engineering Tutorial: Master ChatGPT and LLM Responses.](https://youtu.be/_ZvnD73m40o?feature=shared)
